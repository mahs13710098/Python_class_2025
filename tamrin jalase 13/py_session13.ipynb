{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,12):   \n",
    "    base_url = f'https://www.iranjib.ir/jax/showarchive.php?p=1&id={i}'\n",
    "    r = requests.get(base_url)\n",
    "    r.status_code\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    table = soup.find('table', {'class':'cellpadding5'})\n",
    "    data = []\n",
    "    rows = soup.find_all('tr')\n",
    "    for row in rows:\n",
    "        cells = row.find_all('td')\n",
    "        if len(cells) == 3:\n",
    "            link_tag = cells[0].find('a')\n",
    "            title = link_tag.text.strip()\n",
    "            link = link_tag['href']\n",
    "            date_time = cells[2].text.strip()\n",
    "\n",
    "            data.append({\n",
    "                'title': title,\n",
    "                'url': link,\n",
    "               'datetime': date_time\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "def get_page_data(id, url):\n",
    "    conn = sqlite3.connect('iranjibnew.db')\n",
    "    cursor = conn.cursor()\n",
    "    creat_table_statement = '''CREATE TABLE IF NOT EXISTS headline(\n",
    "                                id,\n",
    "                                title,\n",
    "                                url,\n",
    "                                summery,\n",
    "                                content\n",
    "                            )'''\n",
    "    cursor.execute(creat_table_statement)\n",
    "    r = requests.get(url)\n",
    "    page_soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    title = page_soup.find('h1').get_text()\n",
    "    summery = page_soup.find('div', {'class': 'newssummary'}).get_text()\n",
    "    news_wrapper = page_soup.find('div', id ='news_wrapper')\n",
    "    prgs = news_wrapper.find_all('p')\n",
    "    text = ''\n",
    "    for p in prgs:\n",
    "        text += p.get_text() + '\\n'\n",
    "\n",
    "    insert_into_statement = '''INSERT INTO headline VALUES (?,?,?,?,?)'''\n",
    "    cursor.execute(insert_into_statement, (id,title, url, summery, text))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "for id, item in enumerate(data):\n",
    "    if 'طلا' in item['title'] and 'شهریور' in item['datetime'] :\n",
    "\n",
    "        get_page_data(id, item['url'])\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
